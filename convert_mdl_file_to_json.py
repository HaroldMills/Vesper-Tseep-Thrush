"""
Script that converts a circa-1998 Old Bird detector Simulink .mdl file to JSON.

The resulting JSON can be viewed at http://jsonviewer.stack.hu/, or in
another JSON viewer.
"""


import json


FILE_NAME = 'Old Bird/Detector Source Code/MDL/tseepr.mdl'

TOKEN_KEY = 'key'
TOKEN_STRING = 'string'
TOKEN_VALUE = 'value'
TOKEN_OPEN_BRACE = '{'
TOKEN_CLOSE_BRACE = '}'

STATE_KEY = 'key'
STATE_VALUE = 'value'

LIST_KEYS = {'Annotation', 'Block', 'Line'}
"""
Keys that can occur multiple times in a single mapping in an .mdl file.
Items with such keys are placed into lists in the JSON generated by
this module.
"""

FILTERS = {
    'Annotation': {'Text'},
    'Block': {
        'BlockType', 'MaskDescription', 'MaskPromptString', 'MaskVariables',
        'MaskValueString', 'Name', 'Ports', 'SourceBlock'},
    'Line': {'DstBlock', 'DstPort', 'SrcBlock', 'SrcPort'},
    'Model': {'Name'},
    'System': {'Name'},
}
"""
Mapping from .mdl file keys whose values are mappings and that are to be
retained in the output of this module to sets of keys that are to be
retained in the mappings. Items whose keys are not in the dictionary or
in the sets are not retained.
"""


class Token:
    
    def __init__(self, type_, text=None):
        self.type = type_
        self.text = text
        
    def __str__(self):
        return '({}, {})'.format(self.type, self.text)
        
        
def main():
    tokens = scan(FILE_NAME)
    data = parse(tokens)
    # data = filter_data(data, {'Model'})
    text = json.dumps(data)
    print(text)
    
    
def scan(file_name):
    
    """
    Scans an .mdl file.
    
    The scanning is performed in two stages. The first stage, implemented
    in the `scan_aux` function, produces a sequence of tokens in which each
    line of a multiline string is a separate token. The second stage,
    implemented in this function, concatenates such tokens to make a
    single token.
    """
    
    string_tokens = []
    
    for token in scan_aux(file_name):
        
        if token.type != TOKEN_STRING:
            
            if len(string_tokens) != 0:
                yield join_string_tokens(string_tokens)
                string_tokens = []
                
            yield token
            
        else:
            string_tokens.append(token)
                
    if len(string_tokens) != 0:
        yield join_string_tokens(string_tokens)
        
        
def join_string_tokens(tokens):
    text = ''.join(t.text[1:-1] for t in tokens)
    return Token(TOKEN_VALUE, text)
    
    
def scan_aux(file_name):
    
    with open(file_name, 'r') as file_:
        
        for line in file_:
            
            line = line.strip()
            
            if line.startswith('"'):
                yield Token(TOKEN_STRING, line)
            
            elif line == TOKEN_CLOSE_BRACE:
                yield Token(TOKEN_CLOSE_BRACE)
            
            else:
                
                key, text = line.split(maxsplit=1)
                
                yield Token(TOKEN_KEY, key)
                
                if text == '{':
                    yield Token(TOKEN_OPEN_BRACE)
                elif text.startswith('"'):
                    yield Token(TOKEN_STRING, text)
                else:
                    yield Token(TOKEN_VALUE, text)
                
            
def parse(tokens):
    
    """Parses a sequence of .mdl file tokens into a Python dictionary."""
    
    result = {}
    state = STATE_KEY
    key = None
    
    for token in tokens:
        
        if state == STATE_KEY:
            
            if token.type == TOKEN_KEY:
                key = token.text
                state = 'value';
                
            elif token.type == TOKEN_CLOSE_BRACE:
                return result
                
            else:
                raise ValueError(
                    'Parser encountered {} in key state.'.format(token.type))
                
            
        else:
            
            if token.type == TOKEN_VALUE:
                result[key] = token.text
                state = 'key'
                
            elif token.type == TOKEN_OPEN_BRACE:
                value = parse(tokens)
                if key in LIST_KEYS:
                    if key not in result:
                        result[key] = []
                    result[key].append(value)
                else:
                    result[key] = value
                state = 'key'
                
            else:
                raise ValueError(
                    'Parser encountered {} in value state.'.format(token.type))
                
    return result
    
    
def filter_data(data, filter_keys):
    
    """
    Filters items from a hierarchical Python dictionary according to
    the specified filter keys.
    """
    
    return dict(
        filter_data_aux(k, v)
        for k, v in data.items()
        if k in filter_keys)


def filter_data_aux(key, value):
    
    if isinstance(value, list):
        filter_keys = FILTERS[key] | set(FILTERS.keys())
        return (key, [filter_data(d, filter_keys) for d in value])
    
    elif isinstance(value, dict):
        filter_keys = FILTERS[key] | set(FILTERS.keys())
        return (key, filter_data(value, filter_keys))
    
    else:
        return (key, value)               
                
                    
if __name__ == '__main__':
    main()
    